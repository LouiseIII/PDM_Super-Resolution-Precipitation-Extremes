{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres \n",
    "# Def of the resolution wanted and the domain of interest \n",
    "path = ''\n",
    "\n",
    "resolution_original = 12\n",
    "\n",
    "lat_bnd = [-0.6, 0.58]\n",
    "lon_bnd = [-2.6, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce fichier extrait les maximas des fichiers sources. à "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I- Haute Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_max_month_HR (name, year):\n",
    "\n",
    "    '''\n",
    "    Input : début du nom des fichier d'un mois une année particulière + année concernée\n",
    "    Output : dataset avec pour chaque position du domaine d'étude (rlat / rlon) le max de précipitation horaire ainsi que l'année et le mois concerné\n",
    "    '''\n",
    "\n",
    "    os.chdir(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/HadGEM_driven_COSMO/Future/\"+str(year))\n",
    "    fichiers_month = [fichier for fichier in os.listdir() if fichier.startswith(name)]\n",
    "    liste_data = []\n",
    "\n",
    "    for ind in range(len(fichiers_month)) :\n",
    "        \n",
    "        data=xr.open_dataset(fichiers_month[ind])\n",
    "        \n",
    "        data = data.sel(rlon = slice(*lon_bnd), rlat = slice(*lat_bnd))\n",
    "        vars_to_keep = [\"TOT_PR\", 'rlat', 'rlon']  # Liste des variables à conserver\n",
    "        data = data.drop_vars([var for var in data.variables if var not in vars_to_keep])\n",
    "        data = data.to_dataframe()\n",
    "        data= data.reset_index()\n",
    "\n",
    "        data.rlat = round(data.rlat, 2)\n",
    "        data.rlon = round(data.rlon, 2)\n",
    "\n",
    "        liste_data.append(data)\n",
    "\n",
    "    liste_data = pd.concat(liste_data, ignore_index = True)\n",
    "\n",
    "    ind = liste_data.groupby(['rlat', 'rlon'])['TOT_PR'].idxmax()\n",
    "    liste_data = liste_data.loc[ind]\n",
    "\n",
    "    liste_data['year'] = year\n",
    "    liste_data['month'] = name[8:10]\n",
    "\n",
    "    return liste_data\n",
    "\n",
    "\n",
    "liste_data = []\n",
    "for year in range(2079, 2090):\n",
    "    name = 'lffd'+str(year)\n",
    "\n",
    "    for mois in ['06', '07', '08']:\n",
    "        print(str(year) + ' : ' + mois)\n",
    "        data = get_max_month_HR(name + mois, year)\n",
    "        data.reset_index(inplace = True)\n",
    "        data.drop(columns = ['index'], inplace = True)\n",
    "        liste_data.append(data)\n",
    "\n",
    "liste_data = pd.concat(liste_data, ignore_index = True)\n",
    "\n",
    "os.chdir(path)\n",
    "#liste_data.to_csv('data_summer_future_HR.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II- Basse Resolution\n",
    "\n",
    "**Remark :** Les variables '_12' concerne les variables de resolution sans se référer systématiquement à la résolution de 12 km. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = int(resolution_original / 2)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Les points d'intersections à 2 km\n",
    "liste_lat_2 = np.arange(lat_bnd[0], lat_bnd[1]+0.01, 0.02)\n",
    "liste_lon_2 = np.arange(lon_bnd[0], lon_bnd[1]+0.01, 0.02)\n",
    "\n",
    "# Les points d'intersections à 12 km\n",
    "liste_lat_12 = liste_lat_2[::resolution]\n",
    "liste_lon_12 = liste_lon_2[::resolution]\n",
    "\n",
    "liste_lat_12 = np.append(liste_lat_12, np.max(liste_lat_2) + 0.01)\n",
    "liste_lon_12 = np.append(liste_lon_12, np.max(liste_lon_2) + 0.01)\n",
    "\n",
    "# --------------------------------------------------------------------------- 2\n",
    "\n",
    "# Creation du data dico_coord --> pour chaque localisation à 2 km associer un bloc\n",
    "lat_indices = np.arange(len(liste_lat_2))\n",
    "lon_indices = np.arange(len(liste_lon_2))\n",
    "lat_grid, lon_grid = np.meshgrid(lat_indices, lon_indices)\n",
    "\n",
    "dico_coord = pd.DataFrame({'rlat': np.array(liste_lat_2)[lat_grid.ravel()], \n",
    "                            'rlon': np.array(liste_lon_2)[lon_grid.ravel()]})\n",
    "\n",
    "\n",
    "dico_coord['block'] = 'X'\n",
    "\n",
    "ind_block = 0\n",
    "for lat in tqdm.tqdm(liste_lat_12) :\n",
    "    for lon in liste_lon_12 :\n",
    "        liste = (dico_coord.rlon < lon) & (dico_coord.rlat < lat) & (dico_coord.block == 'X')\n",
    "        if np.sum(liste)>0:\n",
    "            dico_coord.loc[liste, 'block'] = ind_block\n",
    "            ind_block += 1\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- \n",
    "\n",
    "# Creation du data data_block --> pour chaque bloc\n",
    "liste_rlat_12 = dico_coord.groupby('block')['rlat'].mean().values\n",
    "liste_rlon_12 = dico_coord.groupby('block')['rlon'].mean().values\n",
    "liste_block = dico_coord.groupby('block')['block'].first().values\n",
    "\n",
    "data_block = pd.DataFrame({'rlat' : liste_rlat_12, 'rlon' : liste_rlon_12, 'block' : liste_block})\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- voisin\n",
    "\n",
    "# Trouver pour chaque position les blocs les plus proches \n",
    "\n",
    "def find_min (lat, lon, df):\n",
    "    \n",
    "    distance = np.sqrt((df.rlat - lat)**2 + (df.rlon - lon)**2)\n",
    "    min_distance_index = distance.idxmin()\n",
    "    \n",
    "    block = df.loc[min_distance_index, 'block']\n",
    "\n",
    "    df = df.loc[df['block'] != block]\n",
    "    \n",
    "    return block, df\n",
    "\n",
    "\n",
    "dico_coord['block1'], dico_coord['block2'], dico_coord['block3'], dico_coord['block4'] = 'X', 'X', 'X', 'X'\n",
    "\n",
    "for ind in tqdm.tqdm(range(len(dico_coord))):\n",
    "    lon = dico_coord.rlon[ind]\n",
    "    lat = dico_coord.rlat[ind]\n",
    "    block = dico_coord.block[ind]\n",
    "\n",
    "    df = data_block.loc[data_block.block != block].copy()\n",
    "\n",
    "    block2, df = find_min(lat, lon, df)\n",
    "    block3, df = find_min(lat, lon, df)\n",
    "    block4, df = find_min(lat, lon, df)\n",
    "\n",
    "    dico_coord.loc[(dico_coord.rlat == lat) & (dico_coord.rlon == lon), ['block1', 'block2', 'block3', 'block4']] = [block, block2, block3, block4]\n",
    "   \n",
    "dico_coord.rlat = round(dico_coord.rlat, 2)\n",
    "dico_coord.rlon = round(dico_coord.rlon, 2)\n",
    "\n",
    "del liste_lat_2, liste_lon_2, liste_lat_12, liste_lon_12, liste_block\n",
    "del lat_indices, lon_indices, lat_grid, lon_grid, liste\n",
    "\n",
    "os.chdir(path + \"/Topography\")\n",
    "#dico_coord.to_csv('grille2_12.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grille = dico_coord[['rlat', 'rlon', 'block']].copy()\n",
    "grille.rlat = grille.rlat.astype(np.float32)\n",
    "grille.rlon = grille.rlon.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_month (name, year):\n",
    "\n",
    "    os.chdir(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/HadGEM_driven_COSMO/Present/\"+str(year))\n",
    "    fichiers_month = [fichier for fichier in os.listdir() if fichier.startswith(name)]\n",
    "    liste_data = []\n",
    "\n",
    "    for ind in range(len(fichiers_month)) :\n",
    "\n",
    "        fichier = fichiers_month[ind]\n",
    "        data=xr.open_dataset(fichier)\n",
    "        \n",
    "        data = data.sel(rlon = slice(*lon_bnd), rlat = slice(*lat_bnd))\n",
    "        vars_to_keep = ['rlat', 'rlon', 'TOT_PR']  \n",
    "        data = data.drop_vars([var for var in data.variables if var not in vars_to_keep])\n",
    "        data = data.to_dataframe()\n",
    "        data= data.reset_index()\n",
    "\n",
    "        data.rlat = round(data.rlat, 2)\n",
    "        data.rlon = round(data.rlon, 2)\n",
    "        data = pd.merge(data, grille, on = ['rlat', 'rlon'], how = 'left')\n",
    "\n",
    "        liste_block = data.groupby('block')['block'].first().values\n",
    "        liste_tot = data.groupby('block')['T0T_PR'].mean().values\n",
    "\n",
    "        data = pd.DataFrame({'block' : liste_block, 'TOT_PR' : liste_tot})\n",
    "\n",
    "        liste_data.append(data)\n",
    "\n",
    "    os.chdir(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/louiselargeau\")\n",
    "    liste_data = pd.concat(liste_data, ignore_index = True)\n",
    "    liste_data = liste_data.reset_index() \n",
    "\n",
    "    ind_max = liste_data.groupby('block')['TOT_PR'].idxmax()\n",
    "    liste_data = liste_data.loc[ind_max].copy()\n",
    "\n",
    "    liste_data['year'] = year\n",
    "    liste_data['month'] = name[8:10]\n",
    "\n",
    "    return liste_data \n",
    "\n",
    "\n",
    "liste_data = []\n",
    "for year in range(1999, 2010):\n",
    "    name = 'lffd'+str(year)\n",
    "\n",
    "    for mois in ['06', '07', '08']:\n",
    "        print(str(year) + ' : ' + mois)\n",
    "        data = get_max_month(name + mois, year)\n",
    "        data.reset_index(inplace = True)\n",
    "        data.drop(columns = ['index'], inplace = True)\n",
    "        liste_data.append(data)\n",
    "\n",
    "\n",
    "liste_data = pd.concat(liste_data, ignore_index = True)\n",
    "\n",
    "os.chdir(\"/work/FAC/FGSE/IDYST/tbeucler/downscaling/louiselargeau/repos/Downscaling_CM/data/data_low_resolution\")\n",
    "#liste_data.to_csv('data2_summer_present_LR12.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
